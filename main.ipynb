{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing grounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from main import load_agent_model, train\n",
    "import gymnasium as gym\n",
    "from gymnasium.wrappers.flatten_observation import FlattenObservation\n",
    "from footsies_gym.envs.footsies import FootsiesEnv\n",
    "from footsies_gym.wrappers.normalization import FootsiesNormalized\n",
    "from footsies_gym.wrappers.action_comb_disc import FootsiesActionCombinationsDiscretized\n",
    "from footsies_gym.wrappers.statistics import FootsiesStatistics\n",
    "from footsies_gym.wrappers.frame_skip import FootsiesFrameSkipped\n",
    "from importlib import reload\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Footsies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_testing_kwargs = {\n",
    "    \"fast_forward\": False,\n",
    "    \"vs_player\": True,\n",
    "}\n",
    "\n",
    "normal_testing_kwargs = {\n",
    "    \"frame_delay\": 0,\n",
    "    \"dense_reward\": True,\n",
    "}\n",
    "\n",
    "different_addresses_kwargs = {\n",
    "    \"game_port\": 14000,\n",
    "    \"opponent_port\": 14001,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "footsies_env = FootsiesEnv(\n",
    "    game_path=\"../Footsies-Gym/Build/FOOTSIES.x86_64\",\n",
    "    **normal_testing_kwargs,\n",
    "    # **human_testing_kwargs,\n",
    "    **different_addresses_kwargs,\n",
    "    render_mode=\"human\",\n",
    "    log_file=os.path.join(os.getcwd(), \"out.log\"),\n",
    "    log_file_overwrite=True,\n",
    ")\n",
    "\n",
    "statistics = FootsiesStatistics(footsies_env)\n",
    "\n",
    "FRAME_SKIP = True\n",
    "\n",
    "env = FootsiesActionCombinationsDiscretized(\n",
    "    FlattenObservation(\n",
    "        FootsiesNormalized(statistics)\n",
    "        if not FRAME_SKIP\n",
    "        else FootsiesFrameSkipped(FootsiesNormalized(statistics))\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CartPole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_env(obs, info, reward = None, terminated = None, truncated = None):\n",
    "    print(\"Observation:\")\n",
    "    pp.pprint(obs)\n",
    "\n",
    "    if reward is not None or terminated is not None or truncated is not None:\n",
    "        print()\n",
    "    if reward is not None:\n",
    "        print(\"Reward:\", reward)\n",
    "    if terminated is not None:\n",
    "        print(\"Terminated:\", terminated)\n",
    "    if truncated is not None:\n",
    "        print(\"Truncated:\", truncated)\n",
    "\n",
    "    print()\n",
    "    print(\"Info:\")\n",
    "    pp.pprint(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'guard': [1.0, 1.0], 'move': [0, 0], 'move_frame': [0.0, 0.0], 'position': [-0.45454545454545453, 0.45454545454545453]}\n",
      "Observation:\n",
      "array([ 1.        ,  1.        ,  1.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        , -0.45454547,  0.45454547])\n",
      "None\n",
      "\n",
      "Info:\n",
      "{   'frame': 0,\n",
      "    'p1_action': (False, False, False),\n",
      "    'p2_action': (False, False, False)}\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "obs, info = env.reset()\n",
    "report_env(obs, info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'guard': [0.0, 0.0], 'move': [0, 1], 'move_frame': [0.0, 0.0], 'position': [-0.8381816473874178, 0.24909024888818912]}\n",
      "Observation:\n",
      "array([ 0.        ,  0.        ,  0.        ,  1.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        , -0.83818167,  0.24909025])\n",
      "None\n",
      "\n",
      "Reward: 0.0\n",
      "Terminated: False\n",
      "Truncated: False\n",
      "\n",
      "Info:\n",
      "{   'frame': 1002,\n",
      "    'p1_action': (False, False, False),\n",
      "    'p2_action': (True, False, False)}\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "obs, reward, terminated, truncated, info = env.step(env.action_space.sample())\n",
    "report_env(obs, info, reward, terminated, truncated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Env reset\n",
      "0.3\n",
      "0.7\n",
      "Env reset\n",
      "0.3\n",
      "0.7\n",
      "Env reset\n",
      "0.3\n",
      "0.7\n",
      "Env reset\n",
      "0.3\n",
      "0.7\n",
      "Env reset\n",
      "0.3\n",
      "0.7\n"
     ]
    }
   ],
   "source": [
    "for e in range(5):\n",
    "    print(\"Env reset\")\n",
    "    obs, info = env.reset()\n",
    "    terminated, truncated = False, False\n",
    "\n",
    "    while not (terminated or truncated):\n",
    "        obs, reward, terminated, truncated, info = env.step(env.action_space.sample())\n",
    "        if reward != 0.0:\n",
    "            print(reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brisket testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from agents.brisket.agent import FootsiesAgent as BrisketAgent\n",
    "from agents.brisket.loggables import get_loggables as get_brisket_loggables\n",
    "from agents.logger import TrainingLoggerWrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reloading in case changes were made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'agents.base' from '/home/martinho/projects/footsies-agents/agents/base.py'>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import agents.brisket.agent\n",
    "import agents.logger\n",
    "import agents.base\n",
    "reload(agents.brisket.agent)\n",
    "reload(agents.logger)\n",
    "reload(agents.base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "brisket = {\n",
    "    \"Footsies\": lambda: BrisketAgent(\n",
    "        observation_space=env.observation_space,\n",
    "        action_space=env.action_space,\n",
    "        \n",
    "        # For testing\n",
    "        epsilon=0,\n",
    "        epsilon_decay_rate=0,\n",
    "        min_epsilon=0,\n",
    "    ),\n",
    "    \"CartPole\": lambda: BrisketAgent(\n",
    "        observation_space=env.observation_space,\n",
    "        action_space=env.action_space,\n",
    "\n",
    "        shallow=True,\n",
    "        shallow_size=4,\n",
    "        epsilon_decay_rate=0.001,\n",
    "    )\n",
    "}[\"Footsies\"]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "brisket = TrainingLoggerWrapper(\n",
    "    brisket,\n",
    "    float(\"+inf\"),  # never log\n",
    "    cummulative_reward=False,\n",
    "    win_rate=False,\n",
    "    test_states_number=5000,\n",
    "    **get_brisket_loggables(brisket),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent loaded\n"
     ]
    }
   ],
   "source": [
    "load_agent_model(brisket, \"brisket_frameskipped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test output of a single state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "experience = np.array([t[0] for t in brisket.test_states])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1018"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(experience[:, 0] != 1.0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from footsies_gym.utils import get_dict_obs_from_vector_obs\n",
    "from footsies_gym.wrappers.normalization import FootsiesNormalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import footsies_gym.wrappers.normalization\n",
    "import footsies_gym.utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'footsies_gym.wrappers.normalization' from '/home/martinho/projects/Footsies-Gym/footsies-gym/footsies_gym/wrappers/normalization.py'>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(footsies_gym.utils)\n",
    "reload(footsies_gym.wrappers.normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "FootsiesNormalized = footsies_gym.wrappers.normalization.FootsiesNormalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'guard': [3.0, 3.0],\n",
       " 'move': [0, 0],\n",
       " 'move_frame': [0.0, 0.0],\n",
       " 'position': [-2.0000000596046448, 2.0000000596046448]}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "footsies_gym.utils.get_dict_obs_from_vector_obs(e, normalized=True, flattened=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = experience[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argwhere(e[17:17+15] == 1.0).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.4545454680919647"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e[34]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 1.0]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(e[2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing... done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [05:17<00:00,  3.15it/s]\n"
     ]
    }
   ],
   "source": [
    "train(brisket, env, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "882\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(sum(statistics.metric_special_moves_per_episode))\n",
    "print(sum(statistics.metric_special_moves_from_neutral_per_episode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation:\n",
      "array([ 0.03174489, -0.02254564, -0.01391198,  0.02921619], dtype=float32)\n",
      "\n",
      "Info:\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "prev_obs = None\n",
    "obs, info = env.reset()\n",
    "report_env(obs, info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Right'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action = brisket.act(obs)\n",
    "\"Left\" if action == 0 else \"Right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation:\n",
      "array([ 0.03474943,  0.3680826 , -0.01868412, -0.56468004], dtype=float32)\n",
      "\n",
      "Reward: 1.0\n",
      "Terminated: False\n",
      "Truncated: False\n",
      "\n",
      "Info:\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "prev_obs = obs\n",
    "obs, reward, truncated, terminated, info = env.step(action)\n",
    "report_env(obs, info, reward, truncated, terminated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.47500109672546387, -0.2977886199951172]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brisket.q_values(brisket._obs_to_torch(obs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "264"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Number of special moves:\", sum(statistics.metric_special_moves_per_episode))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self-play test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi = brisket.extract_policy(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "footsies_env.set_opponent(pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing... done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:16<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game closed manually, quitting training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train(brisket, env, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importance sampling test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rock, paper, scissors\n",
    "def uniform_random_play_vec(r):\n",
    "    r[:] = np.floor(r * 3)\n",
    "\n",
    "def rocky_play_vec(r):\n",
    "    r[r < 0.8] = 0\n",
    "    r[(r < 0.9) & (r >= 0.8)] = 1\n",
    "    r[(r < 1.0) & (r >= 0.9)] = 2\n",
    "\n",
    "def scissors_play_vec(r):\n",
    "    r[r < 0.9] = 2\n",
    "    r[(r < 0.95) & (r >= 0.9)] = 1\n",
    "    r[(r < 1.0) & (r >= 0.95)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rock, paper, scissors\n",
    "uniform_random_play = lambda: random.randint(0, 2)\n",
    "rocky_play = lambda: 0 if random.random() < 0.8 else random.randint(1, 2)\n",
    "scissors_play = lambda: 2 if random.random() < 0.9 else random.randint(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rock, paper, scissors\n",
    "uniform_random_play_table = np.array([1/3, 1/3, 1/3])\n",
    "rocky_play_table = np.array([0.8, 0.1, 0.1])\n",
    "scissors_play_table = np.array([0.05, 0.05, 0.9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The opponent is not part of the state to emulate *unreactablability*.\n",
    "\n",
    "**TODO**: maybe try, at maximum, using the previous state as the state, as it's uncorrelated anyway?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rps(p1, p2):\n",
    "    offset = 1 - p1\n",
    "    reward = ((p1 + offset) % 3) - ((p2 + offset) % 3)\n",
    "    return reward\n",
    "\n",
    "\n",
    "# state is binary: 00 start, 01 p1 won first, 10 p2 won second, 11 match point\n",
    "def rps_episodic(p1, p2, state):\n",
    "    reward = rps(p1, p2)\n",
    "    p1_won = reward > 0\n",
    "    tie = reward == 0\n",
    "\n",
    "    if state == 0:\n",
    "        return 0, (1 if p1_won else 3 if tie else 2)\n",
    "\n",
    "    if state == 1:\n",
    "        if p1_won:\n",
    "            return reward, 4\n",
    "        \n",
    "        return 0, 3\n",
    "    \n",
    "    if state == 2:\n",
    "        if p1_won or tie:\n",
    "            return 0, 3\n",
    "\n",
    "        return reward, 4\n",
    "\n",
    "    if state == 3:\n",
    "        return reward, 4\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "# is_fix -> importance sampling fix\n",
    "def calculate_q_function_td(player, opponent, N: int = int(1e6), lr: float = 0.1, discount: float = 0.0, is_fix: bool = False, is_table = None, episodic: bool = False):\n",
    "    # S x A\n",
    "    q = np.zeros((1, 3)) if not episodic else np.zeros((4, 3))\n",
    "\n",
    "    for _ in range(N):\n",
    "        if episodic:\n",
    "            state = 0\n",
    "            terminated = False\n",
    "            while not terminated:\n",
    "                ours = player()\n",
    "                theirs = opponent()    \n",
    "\n",
    "                reward, next_state = rps_episodic(ours, theirs, state)\n",
    "                terminated = next_state == 4\n",
    "\n",
    "                modifier = 1 / (3 * is_table[theirs]) if is_fix else 1\n",
    "                if not terminated:\n",
    "                    q[state, ours] = q[state, ours] + lr * (modifier * (reward + discount * q[next_state, ours]) - q[state, ours])\n",
    "                else:\n",
    "                    q[state, ours] = q[state, ours] + lr * (modifier * reward - q[state, ours])\n",
    "\n",
    "                state = next_state\n",
    "\n",
    "        else:\n",
    "            ours = player()\n",
    "            theirs = opponent()\n",
    "\n",
    "            reward = rps(ours, theirs)\n",
    "            modifier = 1 / (3 * is_table[theirs]) if is_fix else 1\n",
    "\n",
    "            q[0, ours] = q[0, ours] + lr * (modifier * reward + discount * q[0, ours] - q[0, ours])\n",
    "        \n",
    "    return q\n",
    "\n",
    "\n",
    "# here N is timesteps, not episodes\n",
    "def calculate_q_function_mc(player, opponent, N: int = int(1e6), is_fix: bool = False, is_table = None, episodic: bool = False):\n",
    "    rand = np.random.random((N, 2))\n",
    "    player(rand[:, 0])\n",
    "    opponent(rand[:, 1])\n",
    "\n",
    "    p1 = rand[:, 0].astype(np.int8)\n",
    "    p2 = rand[:, 1].astype(np.int8)\n",
    "\n",
    "    reward = rps(p1, p2)\n",
    "\n",
    "    df = pd.DataFrame(np.array([p1, reward]).T, columns=[\"a\", \"r\"])\n",
    "\n",
    "    if is_fix:\n",
    "        df[\"r\"] = df[\"r\"] / (3 * is_table[p2[:-1]])\n",
    "\n",
    "    return df.groupby(\"a\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rps_episodic_pandas(df, step: int):\n",
    "    N = df.shape[0]\n",
    "    ixer = np.arange(N // 5) * 5 + step\n",
    "\n",
    "    print(\"a\")\n",
    "\n",
    "    rps_results = rps(df.iloc[ixer][\"p1\"], df.iloc[ixer][\"p2\"])\n",
    "\n",
    "    print(\"b\")\n",
    "\n",
    "    p1_won = rps_results > 0\n",
    "    tie = rps_results == 0\n",
    "    p2_won = rps_results < 0\n",
    "\n",
    "    print(\"c\")\n",
    "\n",
    "    p1_won.index = rps_results.index + 1\n",
    "    tie.index = rps_results.index + 1\n",
    "    p2_won.index = rps_results.index + 1\n",
    "\n",
    "    print(\"d\")\n",
    "\n",
    "    p1_won = p1_won.reindex(index=df.index, fill_value=False)\n",
    "    tie = tie.reindex(index=df.index, fill_value=False)\n",
    "    p2_won = p2_won.reindex(index=df.index, fill_value=False)\n",
    "\n",
    "    print(\"e\")\n",
    "\n",
    "    state = df.iloc[ixer][\"state\"]\n",
    "    state.index = state.index + 1\n",
    "    state.reindex(index=df.index, fill_value=False)\n",
    "\n",
    "    print(\"f\")\n",
    "\n",
    "    # eww\n",
    "    df.loc[p1_won & (state == 0), (\"state\", \"reward\")] = 1, 0\n",
    "    print(\"0\", end=\"\")\n",
    "    df.loc[p1_won & (state == 1), (\"state\", \"reward\")] = 4, 1\n",
    "    print(\"0\", end=\"\")\n",
    "    df.loc[p1_won & (state == 2), (\"state\", \"reward\")] = 3, 0\n",
    "    print(\"0\", end=\"\")\n",
    "    df.loc[p1_won & (state == 3), (\"state\", \"reward\")] = 4, 1\n",
    "    print(\"0\", end=\"\")\n",
    "    df.loc[tie    & (state == 0), (\"state\", \"reward\")] = 3, 0\n",
    "    print(\"0\", end=\"\")\n",
    "    df.loc[tie    & (state == 1), (\"state\", \"reward\")] = 3, 0\n",
    "    print(\"0\", end=\"\")\n",
    "    df.loc[tie    & (state == 2), (\"state\", \"reward\")] = 3, 0\n",
    "    print(\"0\", end=\"\")\n",
    "    df.loc[tie    & (state == 3), (\"state\", \"reward\")] = 4, 0\n",
    "    print(\"0\", end=\"\")\n",
    "    df.loc[p2_won & (state == 0), (\"state\", \"reward\")] = 2, 0\n",
    "    print(\"0\", end=\"\")\n",
    "    df.loc[p2_won & (state == 1), (\"state\", \"reward\")] = 3, 0\n",
    "    print(\"0\", end=\"\")\n",
    "    df.loc[p2_won & (state == 2), (\"state\", \"reward\")] = 4, -1\n",
    "    print(\"0\", end=\"\")\n",
    "    df.loc[p2_won & (state == 3), (\"state\", \"reward\")] = 4, -1\n",
    "    print(\"0\", end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.86, -0.85, -0.01]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_q_function_td(uniform_random_play, scissors_play, N=int(1e5), lr=1e-3, discount=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.850117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.850102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.000105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          r\n",
       "a          \n",
       "0  0.850117\n",
       "1 -0.850102\n",
       "2 -0.000105"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_q_function_mc(uniform_random_play_vec, scissors_play_vec, N=int(1e7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.04,  0.06,  0.01]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_q_function_td(uniform_random_play, scissors_play, N=int(1e5), lr=1e-3, discount=0.0, is_fix=True, is_table=scissors_play_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.000709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.000647</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          r\n",
       "a          \n",
       "0 -0.000709\n",
       "1  0.000795\n",
       "2 -0.000647"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_q_function_mc(uniform_random_play_vec, scissors_play_vec, N=int(1e7), is_fix=True, is_table=scissors_play_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01, -0.01,  0.01],\n",
       "       [ 0.35,  0.31,  0.37],\n",
       "       [-0.32, -0.34, -0.33],\n",
       "       [ 0.02, -0.01,  0.  ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_q_function_td(uniform_random_play, uniform_random_play, N=int(1e5), lr=1e-3, discount=1.0, episodic=True, is_fix=False, is_table=uniform_random_play_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.97, -0.97, -0.01],\n",
       "       [ 0.99, -0.75,  0.05],\n",
       "       [ 0.75, -0.99, -0.06],\n",
       "       [ 0.86, -0.85, -0.01]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_q_function_td(uniform_random_play, scissors_play, N=int(1e5), lr=1e-3, discount=1.0, episodic=True, is_fix=False, is_table=scissors_play_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01, -0.02, -0.02],\n",
       "       [ 0.34,  0.37,  0.26],\n",
       "       [-0.34, -0.34, -0.35],\n",
       "       [-0.01, -0.03, -0.05]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fixed = calculate_q_function_td(uniform_random_play, scissors_play, N=int(1e5), lr=1e-3, discount=1.0, episodic=True, is_fix=True, is_table=scissors_play_table)\n",
    "fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05, 0.05, 0.9 ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scissors_play_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q(0, rock): 0.31911791423709474\n",
      "Q(0, paper): -0.2836083944551429\n",
      "Q(0, scissors): -0.00605036003947255\n"
     ]
    }
   ],
   "source": [
    "# Q(0, rock) if assuming scissors player?\n",
    "# Q(0, rock) = P(0 -> 1, rock) max(Q(1, rock) + Q(1, paper) + Q(1, scissors)) + P(0 -> 2, rock) max(Q(2, rock) + Q(2, paper) + Q(2, scissors)) + P(0 -> 3, rock) max(Q(3, rock) + Q(3, paper) + Q(3, scissors))\n",
    "#            = 0.9 * Q(1, .) + 0.05 * Q(2, .) + 0.05 * Q(3, .)\n",
    "# print(\"Q(0, rock):\", np.sum(np.array([0.9, 0.05, 0.05]) * fixed.sum(axis=1)[1:]))\n",
    "print(\"Q(0, rock):\", np.sum(np.array([0.9, 0.05, 0.05]) * fixed.max(axis=1)[1:]))\n",
    "\n",
    "# Q(0, paper) if assuming scissors player?\n",
    "# Q(0, paper) = P(0 -> 1, paper) max(Q(1, rock) + Q(1, paper) + Q(1, scissors)) + P(0 -> 2, paper) max(Q(2, rock) + Q(2, paper) + Q(2, scissors)) + P(0 -> 3, paper) max(Q(3, rock) + Q(3, paper) + Q(3, scissors))\n",
    "#            = 0.05 * Q(1, .) + 0.9 * Q(2, .) + 0.05 * Q(3, .)\n",
    "print(\"Q(0, paper):\", np.sum(np.array([0.05, 0.9, 0.05]) * fixed.max(axis=1)[1:]))\n",
    "\n",
    "# Q(0, scissors) if assuming scissors player?\n",
    "# Q(0, scissors) = P(0 -> 1, scissors) max(Q(1, rock) + Q(1, paper) + Q(1, scissors)) + P(0 -> 2, scissors) max(Q(2, rock) + Q(2, paper) + Q(2, scissors)) + P(0 -> 3, scissors) max(Q(3, rock) + Q(3, paper) + Q(3, scissors))\n",
    "#            = 0.05 * Q(1, .) + 0.05 * Q(2, .) + 0.9 * Q(3, .)\n",
    "print(\"Q(0, scissors):\", np.sum(np.array([0.05, 0.05, 0.9]) * fixed.max(axis=1)[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Through dynamic programming\n",
    "def corrected_q_values(fixed_q_table, ):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toy experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actor-critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import agents.a2c.a2c as a2c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(a2c)\n",
    "ActorNetwork = a2c.ActorNetwork\n",
    "CriticNetwork = a2c.CriticNetwork\n",
    "A2CModule = a2c.A2CModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium\n",
    "from gymnasium.wrappers.flatten_observation import FlattenObservation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = FlattenObservation(\n",
    "    gymnasium.make(\n",
    "        \"FrozenLake-v1\",\n",
    "        is_slippery=False,\n",
    "        render_mode=None,\n",
    "    )\n",
    ")\n",
    "\n",
    "action_labels = [\"Move left\", \"Move down\", \"Move right\", \"Move up\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_dim = env.observation_space.shape[0]\n",
    "action_dim = env.action_space.n\n",
    "\n",
    "obs_dim, action_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = A2CModule(\n",
    "    actor=ActorNetwork(\n",
    "        obs_dim=obs_dim,\n",
    "        action_dim=action_dim,\n",
    "        hidden_layer_sizes=[],\n",
    "        hidden_layer_activation=nn.Identity,\n",
    "    ),\n",
    "    critic=CriticNetwork(\n",
    "        obs_dim=obs_dim,\n",
    "        hidden_layer_sizes=[],\n",
    "        hidden_layer_activation=nn.Identity,\n",
    "    ),\n",
    "    discount=0.99,\n",
    "    actor_learning_rate=1e-2,\n",
    "    critic_learning_rate=1e-2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation: [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Info: {'prob': 1}\n"
     ]
    }
   ],
   "source": [
    "obs, info = env.reset()\n",
    "\n",
    "print(\"Observation:\", obs)\n",
    "print(\"Info:\", info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Move down'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action = model.act(obs)\n",
    "action_labels[action]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next observation: [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Reward: 0.0\n",
      "Terminated: False\n",
      "Truncated: False\n",
      "Info {'prob': 0.3333333333333333}\n"
     ]
    }
   ],
   "source": [
    "next_obs, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "print(\"Next observation:\", next_obs)\n",
    "print(\"Reward:\", reward)\n",
    "print(\"Terminated:\", terminated)\n",
    "print(\"Truncated:\", truncated)\n",
    "print(\"Info\", info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.update(obs, next_obs, reward, terminated)\n",
    "obs = next_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "terminated, truncated = True, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.0658e+08, -5.3397e+07, -5.2142e+07, -5.2772e+07],\n",
      "        [-3.5489e+07, -5.2408e+07, -5.4007e+07, -5.2408e+07],\n",
      "        [-6.0602e+07, -5.2944e+07, -5.3168e+07, -5.2408e+07],\n",
      "        [-5.2408e+07, -5.4675e+07, -5.3120e+07, -5.2408e+07]])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[96], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m     action \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mact(obs)\n\u001b[1;32m      4\u001b[0m     next_obs, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[0;32m----> 5\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnext_obs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mterminated\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     obs \u001b[38;5;241m=\u001b[39m next_obs\n\u001b[1;32m      8\u001b[0m obs, info \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mreset()\n",
      "File \u001b[0;32m~/projects/footsies-agents/agents/a2c/a2c.py:100\u001b[0m, in \u001b[0;36mA2CModule.update\u001b[0;34m(self, obs, next_obs, reward, terminated)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcritic_optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     99\u001b[0m actor_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcumulative_discount \u001b[38;5;241m*\u001b[39m delta \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_distribution\u001b[38;5;241m.\u001b[39mlog_prob(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction)\n\u001b[0;32m--> 100\u001b[0m \u001b[43mactor_score\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactor_optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcumulative_discount \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdiscount\n",
      "File \u001b[0;32m~/projects/footsies-agents/venv/lib/python3.10/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/footsies-agents/venv/lib/python3.10/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    while not (terminated or truncated):\n",
    "        action = model.act(obs)\n",
    "        next_obs, reward, terminated, truncated, info = env.step(action)\n",
    "        model.update(obs, next_obs, reward, terminated)\n",
    "        obs = next_obs\n",
    "\n",
    "    obs, info = env.reset()\n",
    "    terminated, truncated = False, False\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    print(model.value(torch.eye(16)).reshape(4, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2166, 0.2007, 0.3215, 0.2612],\n",
       "        [0.2304, 0.2006, 0.3252, 0.2438],\n",
       "        [0.2533, 0.2103, 0.3196, 0.2168],\n",
       "        [0.2486, 0.2776, 0.2722, 0.2015],\n",
       "        [0.2018, 0.2652, 0.2348, 0.2982],\n",
       "        [0.1976, 0.2591, 0.3411, 0.2022],\n",
       "        [0.2462, 0.2820, 0.2560, 0.2158],\n",
       "        [0.2570, 0.1995, 0.3111, 0.2323],\n",
       "        [0.2260, 0.1888, 0.3169, 0.2683],\n",
       "        [0.2758, 0.2630, 0.2732, 0.1880],\n",
       "        [0.2658, 0.1991, 0.3117, 0.2234],\n",
       "        [0.2246, 0.2422, 0.3198, 0.2135],\n",
       "        [0.2190, 0.2011, 0.3239, 0.2561],\n",
       "        [0.2487, 0.2158, 0.3165, 0.2191],\n",
       "        [0.2400, 0.2399, 0.2362, 0.2840],\n",
       "        [0.2412, 0.2137, 0.2955, 0.2497]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.policy(torch.eye(16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2166, 0.2007, 0.3215, 0.2612],\n",
       "         [0.2304, 0.2006, 0.3252, 0.2438],\n",
       "         [0.2533, 0.2103, 0.3196, 0.2168],\n",
       "         [0.2486, 0.2776, 0.2722, 0.2015]],\n",
       "\n",
       "        [[0.2018, 0.2652, 0.2348, 0.2982],\n",
       "         [0.1976, 0.2591, 0.3411, 0.2022],\n",
       "         [0.2462, 0.2820, 0.2560, 0.2158],\n",
       "         [0.2570, 0.1995, 0.3111, 0.2323]],\n",
       "\n",
       "        [[0.2260, 0.1888, 0.3169, 0.2683],\n",
       "         [0.2758, 0.2630, 0.2732, 0.1880],\n",
       "         [0.2658, 0.1991, 0.3117, 0.2234],\n",
       "         [0.2246, 0.2422, 0.3198, 0.2135]],\n",
       "\n",
       "        [[0.2190, 0.2011, 0.3239, 0.2561],\n",
       "         [0.2487, 0.2158, 0.3165, 0.2191],\n",
       "         [0.2400, 0.2399, 0.2362, 0.2840],\n",
       "         [0.2412, 0.2137, 0.2955, 0.2497]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.policy(torch.eye(16)).reshape(4, 4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_directions_map(model: A2CModule):\n",
    "    directions_base = {0: \"←\", 1: \"↓\", 2: \"→\", 3: \"↑\"}\n",
    "    \n",
    "    probs = model.policy(torch.eye(16)).reshape(4, 4, 4)\n",
    "\n",
    "    return weight, directions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rps.rps as rps\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'rps.rps' from '/home/martinho/projects/footsies-agents/rps/rps.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(rps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "opponent_pool = {\n",
    "    \"uniform_random_play\": lambda o, i: random.randint(0, 2),\n",
    "    \"rocky_play\": lambda o, i: 0 if random.random() < 0.8 else random.randint(1, 2),\n",
    "    \"scissors_play\": lambda o, i: 2 if random.random() < 0.9 else random.randint(0, 1),\n",
    "    \"imitator\": lambda o, i: i[\"p1_action\"] if i[\"step\"] > 0 else random.randint(0, 2),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "game = rps.RPS(\n",
    "    opponent=opponent_pool[\"imitator\"],\n",
    "    dense_reward=False,\n",
    "    health=3,\n",
    "    flattened=True,\n",
    "    observation_include_play=False,\n",
    "    observation_transformer=lambda o: o.to(torch.float32).unsqueeze(0),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from agents.a2c.a2c import A2CModule, ActorNetwork, CriticNetwork\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Callable, Iterable\n",
    "\n",
    "@dataclass\n",
    "class ObservationModifier:\n",
    "    dim:        int\n",
    "    method:     Callable[[rps.RPSObservation, dict], rps.RPSObservation]\n",
    "    universe:   Callable[[list[rps.RPSObservation]], Iterable[rps.RPSObservation]]\n",
    "\n",
    "observation_neutral = ObservationModifier(\n",
    "    game.observation_dim,\n",
    "    lambda o, i: o,\n",
    "    lambda os: iter(os),\n",
    ")\n",
    "\n",
    "def append_opponent_model_imitator_universe(os: list[rps.RPSObservation]) -> Iterable[rps.RPSObservation]:\n",
    "    for o in os:\n",
    "        for action in range(game.action_dim):\n",
    "            yield torch.hstack((o, torch.nn.functional.one_hot(torch.tensor([action]), num_classes=3)))\n",
    "\n",
    "observation_append_opponent_model_imitator = ObservationModifier(\n",
    "    game.observation_dim + 3,\n",
    "    lambda o, i: torch.hstack((o, torch.nn.functional.one_hot(torch.tensor([opponent_pool[\"imitator\"](o, i)]), num_classes=3))),\n",
    "    append_opponent_model_imitator_universe,\n",
    ")\n",
    "\n",
    "OBSERVATION_MODIFIER = observation_append_opponent_model_imitator\n",
    "OBSERVATION_MODIFIER = observation_neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = A2CModule(\n",
    "    actor=ActorNetwork(\n",
    "        obs_dim=OBSERVATION_MODIFIER.dim,\n",
    "        action_dim=game.action_dim,\n",
    "        hidden_layer_sizes=[],\n",
    "        hidden_layer_activation=nn.Identity,\n",
    "    ),\n",
    "    critic=CriticNetwork(\n",
    "        obs_dim=OBSERVATION_MODIFIER.dim,\n",
    "        hidden_layer_sizes=[],\n",
    "        hidden_layer_activation=nn.Identity,\n",
    "    ),\n",
    "    actor_learning_rate=1e-2,\n",
    "    critic_learning_rate=1e-2,\n",
    "    actor_eligibility_traces_decay=0.0,\n",
    "    critic_eligibility_traces_decay=0.0,\n",
    "    optimizer=torch.optim.SGD,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Game loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 1., 0., 0., 1., 1., 0., 0.]]),\n",
       " {'p1_health': 3,\n",
       "  'p2_health': 3,\n",
       "  'p1_play': 0,\n",
       "  'p2_play': 0,\n",
       "  'p1_action': 0,\n",
       "  'p2_action': 0,\n",
       "  'step': 0})"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs, info = game.reset()\n",
    "obs = OBSERVATION_MODIFIER.method(obs, info)\n",
    "obs, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next observation: tensor([[0., 0., 1., 1., 0., 0., 1., 0., 0.]])\n",
      "Reward: 1.0\n",
      "Terminated: True\n",
      "Truncated: False\n",
      "Info: {'p1_health': 2, 'p2_health': -3, 'p1_play': 0, 'p2_play': 1, 'p1_action': 0, 'p2_action': 1, 'step': 7}\n"
     ]
    }
   ],
   "source": [
    "next_obs, reward, terminated, truncated, info = game.step(agent.act(obs))\n",
    "next_obs = OBSERVATION_MODIFIER.method(next_obs, info) if next_obs is not None else obs\n",
    "print(\"Next observation:\", next_obs)\n",
    "print(\"Reward:\", reward)\n",
    "print(\"Terminated:\", terminated)\n",
    "print(\"Truncated:\", truncated)\n",
    "print(\"Info:\", info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.update(obs, next_obs, reward, terminated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = next_obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train in a loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "from itertools import count, starmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(include_plays: bool = False):\n",
    "    healths_list = [(h1 + 1, h2 + 1) for h1 in range(game.health) for h2 in range(game.health)]\n",
    "    plays_list = [(pl1, pl2) for pl1 in range(game.play_dim) for pl2 in range(game.play_dim)] if include_plays else [[None, None]]\n",
    "\n",
    "    observations = starmap(game.craft_observation, sorted({\n",
    "        tuple((*healths, *plays))\n",
    "        for healths in healths_list\n",
    "        for plays in plays_list\n",
    "    }))\n",
    "\n",
    "    # Modify and add more observations according to the current observation modifier\n",
    "    observations = list(OBSERVATION_MODIFIER.universe(observations))\n",
    "\n",
    "    results = {\n",
    "        observation: (\n",
    "            agent.value(observation).item(),\n",
    "            agent.policy(observation).squeeze(),\n",
    "        )\n",
    "        for observation in observations\n",
    "    }\n",
    "\n",
    "    print(\"Value function:\")\n",
    "    for obs, (value, _) in results.items():\n",
    "        print(f\"{obs}: {value:.2f}\")\n",
    "\n",
    "    print()\n",
    "\n",
    "    print(\"Policy:\")\n",
    "    for obs, (_, distribution) in results.items():\n",
    "        print(f\"{obs}: {distribution}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61427\r"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print_every = 200\n",
    "deltas = []\n",
    "try:\n",
    "    for i in tqdm.tqdm(count(), disable=True):\n",
    "        obs, info = game.reset()\n",
    "        obs = OBSERVATION_MODIFIER.method(obs, info)\n",
    "        terminated, truncated = False, False\n",
    "\n",
    "        while not (terminated or truncated):\n",
    "            action = agent.act(obs)\n",
    "            next_obs, reward, terminated, truncated, info = game.step(action)\n",
    "            next_obs = OBSERVATION_MODIFIER.method(next_obs, info) if next_obs is not None else obs\n",
    "            agent.update(obs, next_obs, reward, terminated)\n",
    "            obs = next_obs\n",
    "\n",
    "        # if i % print_every == 0:\n",
    "        #     clear_output(wait=True)\n",
    "        #     print_results(include_plays=False)\n",
    "        #     print()\n",
    "            print(i, end=\"\\r\")\n",
    "            # print(agent.delta, end=\"\\r\")\n",
    "        \n",
    "        deltas.append(agent.delta)\n",
    "            \n",
    "except KeyboardInterrupt:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f085587abf0>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(deltas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision=2, sci_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value function:\n",
      "tensor([[1., 0., 0., 1., 0., 0., 0.]]): 0.90\n",
      "tensor([[1., 0., 0., 1., 0., 0., 1.]]): 0.90\n",
      "tensor([[1., 0., 0., 1., 0., 0., 2.]]): 0.90\n",
      "tensor([[1., 0., 0., 0., 1., 0., 0.]]): 0.89\n",
      "tensor([[1., 0., 0., 0., 1., 0., 1.]]): 0.89\n",
      "tensor([[1., 0., 0., 0., 1., 0., 2.]]): 0.89\n",
      "tensor([[1., 0., 0., 0., 0., 1., 0.]]): 0.88\n",
      "tensor([[1., 0., 0., 0., 0., 1., 1.]]): 0.88\n",
      "tensor([[1., 0., 0., 0., 0., 1., 2.]]): 0.88\n",
      "tensor([[0., 1., 0., 1., 0., 0., 0.]]): 1.00\n",
      "tensor([[0., 1., 0., 1., 0., 0., 1.]]): 1.00\n",
      "tensor([[0., 1., 0., 1., 0., 0., 2.]]): 1.00\n",
      "tensor([[0., 1., 0., 0., 1., 0., 0.]]): 1.00\n",
      "tensor([[0., 1., 0., 0., 1., 0., 1.]]): 1.00\n",
      "tensor([[0., 1., 0., 0., 1., 0., 2.]]): 1.00\n",
      "tensor([[0., 1., 0., 0., 0., 1., 0.]]): 0.99\n",
      "tensor([[0., 1., 0., 0., 0., 1., 1.]]): 0.99\n",
      "tensor([[0., 1., 0., 0., 0., 1., 2.]]): 0.99\n",
      "tensor([[0., 0., 1., 1., 0., 0., 0.]]): 1.01\n",
      "tensor([[0., 0., 1., 1., 0., 0., 1.]]): 1.01\n",
      "tensor([[0., 0., 1., 1., 0., 0., 2.]]): 1.01\n",
      "tensor([[0., 0., 1., 0., 1., 0., 0.]]): 1.01\n",
      "tensor([[0., 0., 1., 0., 1., 0., 1.]]): 1.01\n",
      "tensor([[0., 0., 1., 0., 1., 0., 2.]]): 1.01\n",
      "tensor([[0., 0., 1., 0., 0., 1., 0.]]): 1.00\n",
      "tensor([[0., 0., 1., 0., 0., 1., 1.]]): 1.00\n",
      "tensor([[0., 0., 1., 0., 0., 1., 2.]]): 1.00\n",
      "\n",
      "Policy:\n",
      "tensor([[1., 0., 0., 1., 0., 0., 0.]]): tensor([    0.00,     0.98,     0.02])\n",
      "tensor([[1., 0., 0., 1., 0., 0., 1.]]): tensor([0.05, 0.03, 0.92])\n",
      "tensor([[1., 0., 0., 1., 0., 0., 2.]]): tensor([    0.96,     0.00,     0.04])\n",
      "tensor([[1., 0., 0., 0., 1., 0., 0.]]): tensor([    0.00,     0.95,     0.05])\n",
      "tensor([[1., 0., 0., 0., 1., 0., 1.]]): tensor([0.05, 0.01, 0.94])\n",
      "tensor([[1., 0., 0., 0., 1., 0., 2.]]): tensor([    0.95,     0.00,     0.05])\n",
      "tensor([[1., 0., 0., 0., 0., 1., 0.]]): tensor([    0.00,     0.97,     0.03])\n",
      "tensor([[1., 0., 0., 0., 0., 1., 1.]]): tensor([0.17, 0.02, 0.80])\n",
      "tensor([[1., 0., 0., 0., 0., 1., 2.]]): tensor([    0.99,     0.00,     0.01])\n",
      "tensor([[0., 1., 0., 1., 0., 0., 0.]]): tensor([    0.00,     0.99,     0.01])\n",
      "tensor([[0., 1., 0., 1., 0., 0., 1.]]): tensor([0.02, 0.05, 0.94])\n",
      "tensor([[0., 1., 0., 1., 0., 0., 2.]]): tensor([    0.88,     0.00,     0.12])\n",
      "tensor([[0., 1., 0., 0., 1., 0., 0.]]): tensor([    0.00,     0.97,     0.03])\n",
      "tensor([[0., 1., 0., 0., 1., 0., 1.]]): tensor([0.02, 0.02, 0.96])\n",
      "tensor([[0., 1., 0., 0., 1., 0., 2.]]): tensor([    0.87,     0.00,     0.13])\n",
      "tensor([[0., 1., 0., 0., 0., 1., 0.]]): tensor([    0.00,     0.98,     0.02])\n",
      "tensor([[0., 1., 0., 0., 0., 1., 1.]]): tensor([0.07, 0.04, 0.89])\n",
      "tensor([[0., 1., 0., 0., 0., 1., 2.]]): tensor([    0.97,     0.00,     0.03])\n",
      "tensor([[0., 0., 1., 1., 0., 0., 0.]]): tensor([    0.00,     0.99,     0.01])\n",
      "tensor([[0., 0., 1., 1., 0., 0., 1.]]): tensor([0.57, 0.03, 0.40])\n",
      "tensor([[0., 0., 1., 1., 0., 0., 2.]]): tensor([    1.00,     0.00,     0.00])\n",
      "tensor([[0., 0., 1., 0., 1., 0., 0.]]): tensor([    0.00,     0.98,     0.02])\n",
      "tensor([[0., 0., 1., 0., 1., 0., 1.]]): tensor([0.56, 0.01, 0.43])\n",
      "tensor([[0., 0., 1., 0., 1., 0., 2.]]): tensor([    1.00,     0.00,     0.00])\n",
      "tensor([[0., 0., 1., 0., 0., 1., 0.]]): tensor([    0.00,     0.99,     0.01])\n",
      "tensor([[0., 0., 1., 0., 0., 1., 1.]]): tensor([0.83, 0.01, 0.16])\n",
      "tensor([[0., 0., 1., 0., 0., 1., 2.]]): tensor([    1.00,     0.00,     0.00])\n"
     ]
    }
   ],
   "source": [
    "print_results(include_plays=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
